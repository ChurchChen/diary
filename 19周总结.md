

# 19周总结

重新理解迁移学习

Transfer Learning 和 One/Few/Zero Learning 算是同义词，都是解决训练数据不足的问题

+ Transfer Learning

  是解决源领域数据量不够的问题，初衷是节省人工标注样本的时间，让模型可以通过已有的标记数据（source domain data）向未标记数据（target domain data）迁移。

+ Domain adaptation

  利用各种的feature transformation手段，学习一个域间不变的特征表达，基于这一特征，可以更好的同时对两个域的数据进行分类

我最近在一篇迁移学习的博士学位论文在看： [迁移学习问题与方法研究]( http://ise.thss.tsinghua.edu.cn/~mlong/doc/phd-thesis-mingsheng-long.pdf ) ，作者是清华的[龙明盛老师](http://ise.thss.tsinghua.edu.cn/~mlong/ )，主要做迁移学习，发表了很多迁移学习的文章，并且基本上都开源了代码



根据李老师说的几个关键词和领域，我找的几篇文章，**关键词**：`transfer learning`；`medical image`; `Adversarial Learning`关于医学图像和迁移学习的文章结合的文章，我没有找到许多

|                            Title                             |                             PDF                              |                             Code                             |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| Transfusion: Understanding Transfer Learning for Medical Imaging |        [PDF](https://arxiv.org/pdf/1902.07208v1.pdf)         |                             暂无                             |
| Data Augmentation Using Learned Transformations for One-Shot Medical Image Segmentation | [PDF](http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_Data_Augmentation_Using_Learned_Transformations_for_One-Shot_Medical_Image_Segmentation_CVPR_2019_paper.pdf) |        [Code](https://github.com/xamyzhao/brainstorm)        |
| ~~Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis~~ |         [PDF](https://arxiv.org/pdf/1908.06912.pdf)          |     [Code](https://github.com/MrGiovanni/ModelsGenesis)      |
| Transferable Adversarial Training: A General Approach to Adapting Deep Classifiers |  [PDF](http://proceedings.mlr.press/v97/liu19b/liu19b.pdf)   | [Code](https://github.com/thuml/Transferable-Adversarial-Training) |

第一篇研究了做迁移和不做迁移对医学图像任务模型的性能有什么影响，结论是： **迁移学习不会显着影响医学成像任务的性能**，从头开始训练的模型几乎与标准ImageNet迁移模型一样好。 

第二篇： 为了解决医学图像标注数据缺乏的问题，提出了一种**通过学习图像的变换来合成带标签医学图像的自动数据增强的半监督分割方法**，并将其运用在一次性MRI脑部医学图像分割任务中。 

第三篇： 设计了一个针对三维医学图像分析的预训练模型，由于是3D数据模型数据量应该非常的大，还没有去找是否可以获取数据，我下载了作者提供的模型，还未深入，应该是**不可行**。

第四篇：把对抗训练和可迁移性结合到一起，还没有仔细看这篇文章，看标题觉得有点意思

以上我比较倾向于第二篇**利用图像变换来增强数据**，可惜代码是基于Tensorflow 的，不是很熟悉。

第一篇文章对比是否做迁移，比较其性能，应该也算是值得花时间理解的一些研究。

另外还有这一篇，这一篇我就先暂时放这儿，之前组会看这一篇：

|                Tiele                |                             PDF                             |                   Code                    |
| :---------------------------------: | :---------------------------------------------------------: | :---------------------------------------: |
| Learning What and Where to Transfer | [PDF](http://proceedings.mlr.press/v97/jang19b/jang19b.pdf) | [Code](https://github.com/alinlab/L2T-ww) |

使用 meta-networks 在异构网络之间完成更加准确有效的知识迁移，即在目标模型和源模型之间，哪些层对的哪些特征进行多大程度的知识迁移。通过实验论证了知识从大网络迁移到小网络，从而增强小网络的学习表现的可行性。

这篇文章是关于模型的迁移的， 本文是从VGG迁移到ResNet，王老师之前说做这种需要对网络模型有很深入的理解，觉得这篇文章还不错，我暂时给它也列上来，需要的**先验知识**太多了，目前很难消化。作者在结尾说：We believe that our work would shed a new angle for complex transfer learning tasks between heterogeneous or/and multiple network architectures and tasks。我也不是很明白说的是提供了什么新的视角。



关于找文章这件事：

+ 实时性

  近两年的文章，好的会议、期刊文章

+ 可行性

  **实验数据是否能获取**，显卡资源是否足够

+ 实验平台

  Pytorch 还是 Tensorflow

**找到文章，一定要自己先实践，有什么问题，再跟老师汇报**，今天发生了非常欠考虑的事情，找到文章还没有深入就找李老师报告了，这篇文章是MICCAI 2019 “百里挑一”的好文章，是基于Tensorflow 框架 Python 2.7 版本的源代码，我之前本来想着能不能用pytorch重构这一下这个代码，顺便用来提高自己的编码能力，关于3D数据这个问题没有考虑到。以后一定会避免这种问题



后记：

这周前面两三天没有做什么具体的工作（班里有聚会，篮球赛，研三欢送活动去玩那么几天，还疯狂快速的刷了庆余年... 这学期以来唯一看过的一部剧）然后大数据还有最后一个期末 Project 完成了一部分，还有一些其他：帮师兄弄了一部分论文，编辑一下数学公式、找找参考文献；王老师给了我一篇论文让我翻译一部分，我用机翻过来，还没来得及好好改，王老师急着用我就先发过去了，效果当然是不好，被王老师”教育“了一顿。这两三 天算是稍微回归一点状态，看了一些东西，找了几篇论文。